## Robust Defect Image Synthesis Using Null Embedding Optimization for Industrial Applications<br><sub>Official PyTorch Implementation</sub>

This repository contains the official PyTorch implementation of our paper **"Robust Defect Image Synthesis Using Null Embedding Optimization for Industrial Applications"** (submitted to Pattern Recognition).

### Abstract

Accurate defect classification and segmentation are critical in the manufacturing sector, yet both tasks are often hindered by imbalanced data and the scarcity of defect samples. Traditional synthetic data augmentation methods tend to produce images with structural inconsistencies, limiting their effectiveness. In this work, we introduce a novel approach that integrates null embedding optimization with **Residual Linear Interpolation (RLI)** connections to generate latent representations that closely mimic the original images while preserving structural fidelity. Furthermore, a prompt-to-prompt augmentation technique is employed to systematically modify the base text prompt, enabling the generation of diverse defect morphologies. This unified framework primarily enhances the variability of the dataset by generating diverse defect morphologies, while simultaneously yielding high-fidelity synthetic images that visually correspond to real defects, thereby significantly improving the performance of both classification and segmentation models.

### Key Features

* üéØ **Training-free approach**: No LoRA fine-tuning required - achieves high-quality synthesis through optimization-based refinement
* üîß **RLI Connections**: Residual Linear Interpolation preserves fine-grained structural details in the UNet architecture
* üé® **Null Embedding Optimization**: Mitigates structural inconsistencies by optimizing latent representations
* üîÑ **Prompt-to-Prompt Augmentation**: Systematically modifies text prompts to generate diverse defect morphologies
* üìä **Dual Task Support**: Improves both defect classification and segmentation performance
* ‚ö°Ô∏è **Deterministic Generation**: Ensures consistent, reproducible outputs without stochastic variance

This repository contains:
* ü™ê A simple PyTorch implementation
* ‚ö°Ô∏è Easy Synthetic data generation using our methodology
* üöÄ **No LoRA weights required** - optimization-based approach


## Method Overview

![Pipeline](./fig/methodology1-c.png)
*Figure 1: The pipeline of our proposed method*

Our method integrates three key components:

1. **DDIM Inversion**: Rapid and precise extraction of latent values from input images
2. **Null Embedding Optimization**: Optimizes unconditional embeddings to preserve structural fidelity
3. **RLI Connections**: Residual Linear Interpolation applied to Up-blocks of UNet to preserve high-frequency structural details

![RLI Connections](./fig/methodology2-b.png)
*Figure 2: Residual Linear Interpolation (RLI) Connections*

Unlike previous methods that require LoRA fine-tuning, our approach is **training-free** and achieves superior results through optimization-based refinement.


## Setup

First, download and set up the repo:
Code has been tested on CUDA 11.8, Python 3.10.14 but other versions should be fine.

```bash
git clone https://github.com/acerghjk-cloud/RLI.git
cd RLI
```

We provide an environment.yml file that can be used to create a Conda environment. 
```bash
conda env create -f environment.yaml
conda activate dune
```

Computational Costs(single image)[tested, GPU A6000, A100 80GB]

| Resolution   | Time     | Peak Memory |
|--------------|----------|-------------|
| 512x512      | 238.65s  | 31.96GB     |
| 1024x1024    | 600.01s  | 70.07GB     |




<br>

## 1Ô∏è‚É£ If you want to see the demo

Run the following commands to generate defect images:

```bash
bash scripts/run.sh
```
```bash
bash scripts/run_1024.sh
```


<br>

## 2Ô∏è‚É£ What if you actually wanted to double up your existing dataset?



```bash
bash scripts/run_dataset.sh

```
```bash
bash scripts/run_dataset_1024.sh

```
If you want to use your dataset, please modify the --original_dataset_path in run_dataset.sh.
Check results.txt later to check PSNR, SSIM, and LPIPS score.

<br>

## 3Ô∏è‚É£ If you want to see various defect like the picture below

![Various Defects](./fig/aug_defect-b.png)
*Figure 3: Various defect images are generated by modifying prompts using word pairs like crack with blistering, crack with dent, defect with rust, photo with corrosion, defect with peeling and crack with scratch.*

The figure above shows various defect types generated by our method.





Try changing `--prompt` and `--ch_prompt`
```bash
CUDA_VISIBLE_DEVICES=0 python src/run_various.py \
--image_path "./img/[0001]TopBF0.png" \
--prompt "photo of a crack defect image" \
--ch_prompt "photo of a crack corrosion image" \
--neg_prompt " " \
--eq 2.0 \
--replace 0.8 \
```


```bash
bash scripts/run_various.sh
```
```bash
bash scripts/run_various_1024.sh
```

As a result of changing to various prompts, you can see that it changes in a variety of ways compared to the original.


<br>

## 4Ô∏è‚É£ Various synthetic data generation

Try changing `--prompt` and `--ch_prompt`
```bash
CUDA_VISIBLE_DEVICES=0 python src/run_dataset_various.py \
--original_dataset_path "./original_dataset" \
--new_dataset_path "./new_dataset" \
--prompt "photo of a crack defect image" \
--ch_prompt "photo of a crack corrosion image" \
--neg_prompt " " \
--eq 2.0 \
--replace 0.8 \
--datacheck
```





```bash
bash run_dataset_various.sh

```
```bash
bash run_dataset_various_1024.sh

```
If you want to use your dataset, please modify the --original_dataset_path in run_dataset.sh.
Check results.txt later to check PSNR, SSIM, and LPIPS score.



## Acknowledgments
This work was supported by the Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korean government (MSIT) (No.RS-2022-00155915, Artificial Intelligence Convergence Innovation Human Resources Development (Inha University) and  No.2021-0-02068, Artificial Intelligence Innovation Hub and IITP-2024-RS-2024-00360227, Leading Generative AI Human Resources Development. This work was supported by Inha University Research Grant.


<!-- Acknowledgments logos -->


## License
The code and model weights are licensed under the MIT License. See [`LICENSE.txt`](LICENSE.txt) for details.
